# LangGraph Flow â€” TÃ i liá»‡u chi tiáº¿t

MÃ´ táº£ Ä‘áº§y Ä‘á»§ cáº¥u trÃºc LangGraph, logic phÃ¢n loáº¡i intent 2-nhÃ¡nh (shopping + ### 5. Clarify Stream Node (Early Exit)
**KÃ­ch hoáº¡t**: `clari### 5. Clarify Stream Node (Early Exit)
**KÃ­ch hoáº¡t**: `clarify_needed = true`

**LLM-Based Social Intent Detection**:
Bot sá»­ dá»¥ng LLM Ä‘á»ƒ detect vÃ  generate social responses thay vÃ¬ pattern matching cá»©ng nháº¯c:

**LLM Processing**:
- PhÃ¢n tÃ­ch user message Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ³ social/personal intent khÃ´ng
- Generate pháº£n há»“i phÃ¹ há»£p vá»›i vÄƒn hÃ³a vÃ  context
- Giá»ng ná»¯, xÆ°ng "em", gá»i "quÃ½ khÃ¡ch"
- Äáº·t ranh giá»›i há»£p lÃ½ khi cáº§n thiáº¿t

**VÃ­ dá»¥ LLM Social Responses**:
- "em khá»e khÃ´ng" â†’ "Em khá»e, cáº£m Æ¡n quÃ½ khÃ¡ch Ä‘Ã£ há»i áº¡"
- "Ä‘i chÆ¡i khÃ´ng" â†’ "Em Ä‘ang lÃ m viá»‡c áº¡, khÃ´ng thá»ƒ Ä‘i chÆ¡i Ä‘Æ°á»£c"  
- "tÃªn gÃ¬" â†’ "Em lÃ  trá»£ lÃ½ AI cá»§a SSTC áº¡"
- "lÃ m gÃ¬ Ä‘Ã¢y" â†’ "Em Ä‘ang há»— trá»£ khÃ¡ch hÃ ng áº¡"
- "cÃ³ báº¡n trai khÃ´ng" â†’ "Em lÃ  AI nÃªn khÃ´ng cÃ³ chuyá»‡n Ä‘Ã³ áº¡"

**Response Format**: `{LLM Social Response}. {Business Redirect}`

**Standard Clarify** (khi LLM khÃ´ng detect social intent):
- **VI**: "Dáº¡ em ráº¥t vui Ä‘Æ°á»£c giÃºp áº¡ â€” quÃ½ khÃ¡ch Ä‘ang cáº§n tÆ° váº¥n mua hÃ ng, kiá»ƒm tra báº£o hÃ nh hay muá»‘n trÃ² chuyá»‡n thÃ´i áº¡?"
- **EN**: "Hi! I'm happy to help â€” are you looking for shopping advice, a warranty check, or just to chat?"

**Æ¯u Ä‘iá»ƒm LLM approach**:
- âœ… **Flexible**: Hiá»ƒu Ä‘Æ°á»£c context vÃ  nuance
- âœ… **Natural**: Generate responses tá»± nhiÃªn, khÃ´ng cá»©ng nháº¯c
- âœ… **Adaptive**: CÃ³ thá»ƒ handle cÃ¡c social intents má»›i
- âœ… **Cultural**: PhÃ¹ há»£p vá»›i vÄƒn hÃ³a vÃ  cÃ¡ch xÆ°ng hÃ´ Viá»‡t Nam
- âœ… **Consistent**: Maintain giá»ng Ä‘iá»‡u vÃ  persona Ä‘á»“ng nháº¥t

### 6. Warranty Stream Node (Early Exit)  
**KÃ­ch hoáº¡t**: intent=warranty vÃ  khÃ´ng cáº§n clarify

**Serial Detection**:
- **Regex**: `(?<![A-Za-z0-9-])(?=[A-Za-z0-9-]*\d[A-Za-z0-9-]*)([A-Za-z0-9-]{3,32})(?![A-Za-z0-9-])`
- **Rules**: 3-32 chars, [A-Za-z0-9-], pháº£i cÃ³ Ã­t nháº¥t 1 sá»‘, khÃ´ng cÃ³ space

**Flow**:
1. **KhÃ´ng cÃ³ serial**: "QuÃ½ khÃ¡ch vui lÃ²ng cung cáº¥p sá»‘ serial..."
2. **Serial invalid**: "Em chÆ°a nháº­n diá»‡n Ä‘Æ°á»£c sá»‘ serial há»£p lá»‡..."
3. **Serial há»£p lá»‡**: 
   - Query `warranty_records` table (DB-only)
   - Format: "ThÃ´ng tin báº£o hÃ nh: Sáº£n pháº©m '{name}', Serial '{serial}', háº¿t báº£o hÃ nh vÃ o ngÃ y {d/m/y}"
   - Append persona follow-up

**Metadata Tracking**:
- LÆ°u `warranty_meta: {kind: "prompt|result", found: bool, serial: str}`
- Assistant message metadata: `type = "warranty_prompt|warranty_result"`

### 7. Retrieve Node
**KÃ­ch hoáº¡t**: intent=shopping vÃ  need_retrieval=true

**Processing**:
- Query ChromaDB vá»›i `bge-m3` embeddings (1024-d)
- Filter: conversation_id, user_id
- Collection: `CHROMA_COLLECTION` env (default: `conversations_dev`)
- Re-rank results vá»›i `simple_rerank()`

**Output**: `retrieved_context` chunks cho shopping advice

### 8. Stream Respond Node
**Input**: persona (max `PERSONA_MAX_CHARS`), preferred_language, history, retrieved_context, detected intent

**Prompt Building**:
```
System Persona: [persona content]
Retrieved context: [chunks if any]
Detected intent: shopping|warranty  # bias toward focused response
Instruction: [VI/EN based on preferred_language]
Conversation: [chat history]
Assistant:
```

**Streaming**: Chunks qua `generate_text_stream()` â†’ SSE format

### 9. Persona Follow-up (Auto-append)
**Source**: `FollowUp:` line tá»« persona file
**Timing**: Sau khi stream_respond_node hoÃ n thÃ nh
**Example**: "Em cÃ²n cÃ³ thá»ƒ há»— trá»£ tÆ° váº¥n mua hÃ ng, kiá»ƒm tra báº£o hÃ nh hoáº·c trÃ² chuyá»‡n cÃ¹ng quÃ½ khÃ¡ch â€” quÃ½ khÃ¡ch muá»‘n em giÃºp gÃ¬ thÃªm khÃ´ng áº¡?"d = true`

**Gentle Clarify Questions**:
- **VI**: "Dáº¡ em ráº¥t vui Ä‘Æ°á»£c giÃºp áº¡ â€” quÃ½ khÃ¡ch Ä‘ang cáº§n tÆ° váº¥n mua hÃ ng, kiá»ƒm tra báº£o hÃ nh hay muá»‘n trÃ² chuyá»‡n thÃ´i áº¡?"
- **EN**: "Hi! I'm happy to help â€” are you looking for shopping advice, a warranty check, or just to chat?"

**Äáº·c Ä‘iá»ƒm**:
- Má»Ÿ rá»™ng hÆ¡n 2 intent (cho phÃ©p "just to chat")
- Giá»ng ná»¯, nháº¹ nhÃ ng, khÃ´ng Ã©p buá»™c
- Cho phÃ©p social interaction tá»± nhiÃªn
- **END** turn sau khi há»i

### 6. Warranty Stream Node (Early Exit)  
**KÃ­ch hoáº¡t**: intent=warranty vÃ  khÃ´ng cáº§n clarify

**Serial Detection**:
- **Regex**: `(?<![A-Za-z0-9-])(?=[A-Za-z0-9-]*\d[A-Za-z0-9-]*)([A-Za-z0-9-]{3,32})(?![A-Za-z0-9-])`
- **Rules**: 3-32 chars, [A-Za-z0-9-], pháº£i cÃ³ Ã­t nháº¥t 1 sá»‘, khÃ´ng cÃ³ space

**Flow**:
1. **KhÃ´ng cÃ³ serial**: "QuÃ½ khÃ¡ch vui lÃ²ng cung cáº¥p sá»‘ serial..."
2. **Serial invalid**: "Em chÆ°a nháº­n diá»‡n Ä‘Æ°á»£c sá»‘ serial há»£p lá»‡..."
3. **Serial há»£p lá»‡**: 
   - Query `warranty_records` table (DB-only)
   - Format: "ThÃ´ng tin báº£o hÃ nh: Sáº£n pháº©m '{name}', Serial '{serial}', háº¿t báº£o hÃ nh vÃ o ngÃ y {d/m/y}"
   - Append persona follow-up

**Metadata Tracking**:
- LÆ°u `warranty_meta: {kind: "prompt|result", found: bool, serial: str}`
- Assistant message metadata: `type = "warranty_prompt|warranty_result"`

### 7. Retrieve Node
**KÃ­ch hoáº¡t**: intent=shopping vÃ  need_retrieval=true

**Processing**:
- Query ChromaDB vá»›i `bge-m3` embeddings (1024-d)
- Filter: conversation_id, user_id
- Collection: `CHROMA_COLLECTION` env (default: `conversations_dev`)
- Re-rank results vá»›i `simple_rerank()`

**Output**: `retrieved_context` chunks cho shopping advice

### 8. Stream Respond Node
**Input**: persona (max `PERSONA_MAX_CHARS`), preferred_language, history, retrieved_context, detected intent

**Prompt Building**:
```
System Persona: [persona content]
Retrieved context: [chunks if any]
Detected intent: shopping|warranty  # bias toward focused response
Instruction: [VI/EN based on preferred_language]
Conversation: [chat history]
Assistant:
```

**Streaming**: Chunks qua `generate_text_stream()` â†’ SSE format

### 9. Persona Follow-up (Auto-append)
**Source**: `FollowUp:` line tá»« persona file
**Timing**: Sau khi stream_respond_node hoÃ n thÃ nh
**Example**: "Em cÃ²n cÃ³ thá»ƒ há»— trá»£ tÆ° váº¥n mua hÃ ng, kiá»ƒm tra báº£o hÃ nh hoáº·c trÃ² chuyá»‡n cÃ¹ng quÃ½ khÃ¡ch â€” quÃ½ khÃ¡ch muá»‘n em giÃºp gÃ¬ thÃªm khÃ´ng áº¡?"), xá»­ lÃ½ ngÃ´n ngá»¯, vÃ  cÃ¡c tÃ­nh nÄƒng nÃ¢ng cao.

## Tá»•ng quan há»‡ thá»‘ng

### ChÃ­nh sÃ¡ch Intent (2 nhÃ¡nh chÃ­nh)
- **shopping**: TÆ° váº¥n mua hÃ ng, gá»£i Ã½ sáº£n pháº©m, so sÃ¡nh â†’ yÃªu cáº§u retrieval tá»« knowledge base
- **warranty**: Há»— trá»£ báº£o hÃ nh, kiá»ƒm tra serial â†’ DB-only lookup, khÃ´ng qua retrieval
- **unknown**: Khi khÃ´ng rÃµ intent â†’ clarify nháº¹ nhÃ ng, giá»ng ná»¯, khÃ´ng Ã©p buá»™c

### Äáº·c Ä‘iá»ƒm tÆ°Æ¡ng tÃ¡c
- **Greeting thÃ¢n thiá»‡n**: Assistant gá»­i lá»i chÃ o dá»… thÆ°Æ¡ng khi intent rÃµ rÃ ng
- **Language-switch**: PhÃ¡t hiá»‡n yÃªu cáº§u "speak English" â†’ tráº£ lá»i ngay "sure, you can speak english with me" + chuyá»ƒn ngÃ´n ngá»¯
- **Clarify nháº¹ nhÃ ng**: CÃ¢u há»i má»Ÿ, cho phÃ©p trÃ² chuyá»‡n tá»± nhiÃªn, khÃ´ng chá»‰ há»i 2 intent
- **Social boundaries**: Xá»­ lÃ½ yÃªu cáº§u xÃ£ giao ("hang out") má»™t cÃ¡ch thÃ¢n thiá»‡n nhÆ°ng cÃ³ giá»›i háº¡n

## Luá»“ng Ä‘iá»u khiá»ƒn (per message)

1. **Greeting** (tá»± Ä‘á»™ng khi táº¡o conversation): Assistant tá»± chÃ o tá»« persona, lÆ°u DB + embed
2. **Nháº­n tin nháº¯n**: LÆ°u user message, enqueue embedding 
3. **Language detection & switch**: PhÃ¡t hiá»‡n yÃªu cáº§u English â†’ ack ngay + chuyá»ƒn ngÃ´n ngá»¯
4. **Cute greeting**: Náº¿u intent rÃµ (shopping/warranty) â†’ gá»­i lá»i chÃ o dá»… thÆ°Æ¡ng "Dáº¡ em ráº¥t vui Ä‘Æ°á»£c giÃºp quÃ½ khÃ¡ch! ğŸ’–"
5. **PhÃ¢n loáº¡i intent**: 
   - **Early exit A**: cáº§n clarify â†’ stream cÃ¢u há»i má»Ÿ, nháº¹ nhÃ ng â†’ END
   - **Early exit B**: intent=warranty â†’ xá»­ lÃ½ báº£o hÃ nh DB-only â†’ END
6. **Retrieve** (chá»‰ shopping) â†’ **Respond** (stream) + follow-up â†’ END

## Nodes & Implementation

### Mapping chÃ­nh
- **classify** â†’ `agent.langgraph_flow.classify_node`
- **retrieve** â†’ `agent.langgraph_flow.retrieve_node` 
- **respond_stream** â†’ `agent.langgraph_flow.stream_respond_node`
- **clarify_stream** â†’ `agent.langgraph_flow.clarify_stream_node` (early exit)
- **warranty_stream** â†’ `agent.langgraph_flow.warranty_stream_node` (early exit)

### Luá»“ng streaming trong endpoint
```
POST /conversations/{id}/stream:
  â”œâ”€â”€ classify_node() 
  â”œâ”€â”€ detect_english_request() â†’ emit "sure, you can speak english with me"
  â”œâ”€â”€ emit_cute_greeting() â†’ "Dáº¡ em ráº¥t vui Ä‘Æ°á»£c giÃºp! ğŸ’–" (náº¿u intent rÃµ)
  â”œâ”€â”€ warranty_stream_node() â†’ END (náº¿u warranty)
  â”œâ”€â”€ clarify_stream_node() â†’ END (náº¿u cáº§n clarify)  
  â”œâ”€â”€ retrieve_node() (náº¿u shopping)
  â”œâ”€â”€ stream_respond_node()
  â””â”€â”€ append_persona_followup()
```

## Chi tiáº¿t tá»«ng Node

### 1. Greeting (Auto-generated)
- **KÃ­ch hoáº¡t**: Khi táº¡o conversation má»›i
- **Input**: `PERSONA_PATH` 
- **Behavior**: Äá»c `Greeting:` tá»« persona file â†’ lÆ°u DB + embed
- **Example**: "ChÃ o quÃ½ khÃ¡ch! Em lÃ  nhÃ¢n viÃªn SSTC, ráº¥t vui Ä‘Æ°á»£c há»— trá»£ quÃ½ khÃ¡ch..."

### 2. Language Detection & Switch
- **KÃ­ch hoáº¡t**: PhÃ¡t hiá»‡n cá»¥m tá»« "speak english", "tiáº¿ng anh Ä‘Æ°á»£c khÃ´ng", etc.
- **Response**: Emit ngay chunk "sure, you can speak english with me" 
- **Effect**: Set `preferred_language = "en"` cho conversation
- **Persist**: LÆ°u ack message vÃ o DB Ä‘á»ƒ xuáº¥t hiá»‡n trong history

### 3. Cute Greeting  
- **KÃ­ch hoáº¡t**: Intent confident (shopping/warranty) vÃ  khÃ´ng cáº§n clarify
- **VI**: "Dáº¡ em ráº¥t vui Ä‘Æ°á»£c giÃºp quÃ½ khÃ¡ch! ğŸ’– Em sáº½ há»— trá»£ ngay áº¡."
- **EN**: "Hi! I'm happy to help ğŸ’– I'll assist you right away."
- **Persist**: LÆ°u greeting vÃ o DB + embed

### 4. Classify Node (Intent Detection)
**Input**: Latest user message, chat history, `INTENT_CONFIDENCE_THRESHOLD`

**LLM Processing**:
```json
{
  "intent": "shopping|warranty|unknown",
  "confidence": 0.0-1.0,
  "need_retrieval": false,
  "clarify_needed": false, 
  "clarify_questions": ["..."],
  "rationale": "..."
}
```

**Keyword Fallback** (bilingual):
- **Shopping**: mua, Ä‘áº·t, giÃ¡, khuyáº¿n mÃ£i, buy, order, price, discount...
- **Warranty**: báº£o hÃ nh, serial, warranty, check warranty...

**Logic**:
- Náº¿u `unknown` hoáº·c `confidence < threshold` â†’ `clarify_needed = true`
- Shopping â†’ `need_retrieval = true` (cáº§n knowledge base)
- Warranty â†’ `need_retrieval = false` (DB-only lookup)

**Output**: intent, confidence, clarify_needed, preferred_language

## MÃ´ táº£ node (chi tiáº¿t ngáº¯n)

- Node 0 â€” Greeting (ngoÃ i bÄƒng)
	- Má»¥c Ä‘Ã­ch: Thiáº¿t láº­p tÃ´ng giá»ng/nhÃ¢n xÆ°ng theo persona ngay khi táº¡o conversation.
	- Input: conversation_id, persona (`PERSONA_PATH`). Output: 1 message assistant loáº¡i â€œgreetingâ€.
	- TÃ¡c dá»¥ng phá»¥: lÆ°u DB; upsert embedding (id = message_id).

- Node 1 â€” Nháº­n tin nháº¯n
	- Input: HTTP request (X-API-Key), conversation_id, user message.
	- Xá»­ lÃ½: Ä‘áº£m báº£o conversation; lÆ°u message; enqueue embedding (async, tuá»³ chá»n sync). Errors: 401, lá»—i DB.

- Node 2 â€” PhÃ¢n loáº¡i intent
	- Input: latest user message, history, persona, `INTENT_CONFIDENCE_THRESHOLD`.
	- Xá»­ lÃ½: LLM tráº£ JSON (intent/confidence/clarify/need_retrieval); fallback tá»« khÃ³a song ngá»¯; táº¡o 1 cÃ¢u clarify chuáº©n hoÃ¡ (VI/EN) khi cáº§n.
	- Xá»­ lÃ½: LLM tráº£ JSON (intent/confidence/clarify/need_retrieval); fallback tá»« khÃ³a song ngá»¯; táº¡o 1 cÃ¢u clarify chuáº©n hoÃ¡ (VI/EN) khi cáº§n. Chá»‰ cÃ²n hai intent háº¹p: `shopping` (tÆ° váº¥n/mua hÃ ng) vÃ  `warranty` (báº£o hÃ nh). Náº¿u khÃ´ng cháº¯c, tráº£ `unknown` vÃ  há»i má»™t cÃ¢u lÃ m rÃµ ngáº¯n, nháº¹ nhÃ ng, giá»ng ná»¯, khÃ´ng Ã©p.
	- **Output**: intent, confidence, clarify_needed, preferred_language
	- Early exits: (1) clarify_needed â†’ `clarify_stream`; (2) intent=warranty + serial (hoáº·c Ä‘ang chá» serial) â†’ `warranty_stream`.

- Clarify (early) â€” `clarify_stream`
	- Má»¥c Ä‘Ã­ch: Há»i 1 cÃ¢u lÃ m rÃµ rá»“i END lÆ°á»£t.
	- Input: clarify_questions[0], preferred_language, persona. Output: assistant message loáº¡i â€œclarifyâ€.
	- TÃ¡c dá»¥ng phá»¥: lÆ°u DB; upsert embedding.

	Notes:
	- The clarify question is intentionally open-ended and gentle (e.g. EN: "Hi! I'm happy to help â€” are you looking for shopping advice, a warranty check, or just to chat?"; VI: "Dáº¡ em ráº¥t vui Ä‘Æ°á»£c giÃºp áº¡ â€” quÃ½ khÃ¡ch Ä‘ang cáº§n tÆ° váº¥n mua hÃ ng, kiá»ƒm tra báº£o hÃ nh hay muá»‘n trÃ² chuyá»‡n thÃ´i áº¡?").
	- When the user explicitly asks to speak English, the stream endpoint will first emit a short English acknowledgement ("sure, you can speak english with me") and set the conversation's preferred language to English for subsequent messages.

- Warranty (early) â€” `warranty_stream`
	- Má»¥c Ä‘Ã­ch: Xá»­ lÃ½ nhanh báº£o hÃ nh theo serial; khÃ´ng Ä‘i qua retrieve/LLM ná»™i dung khÃ¡c.
	- Input: latest user message, tráº¡ng thÃ¡i â€œÄ‘ang chá» serialâ€.
	- Xá»­ lÃ½: trÃ­ch xuáº¥t serial (regex 3â€“32 [A-Za-z0-9-], cÃ³ Ã­t nháº¥t 1 chá»¯ sá»‘); náº¿u há»£p lá»‡ â†’ tra DB `warranty_records` (DB-only); format ngÃ y D/M/YYYY; thÃªm follow-up ngáº¯n tá»« persona.
	- Output: káº¿t quáº£ báº£o hÃ nh hoáº·c hÆ°á»›ng dáº«n nháº­p serial/hotline. Side-effects: lÆ°u DB; upsert embedding; END lÆ°á»£t.

		Notes:
		- Warranty lookup is DB-only: the node queries `warranty_records` in the SQL DB and does not call retrieval/LLM for the actual lookup result.
		- After a warranty result (found or not), the node appends a short persona-driven follow-up sentence (if present) to keep the conversation friendly.

- Node 3 â€” Retrieve
	- Input: query (tá»« user), conversation_id, embed model `bge-m3`.
	- Xá»­ lÃ½: truy váº¥n ChromaDB (`./database/chroma_db/`), lá»c theo metadata; re-rank náº¿u báº­t.
	- Output: retrieved_context (chunks).

- Node 4 â€” Respond (stream)
	- Input: persona (cáº¯t theo `PERSONA_MAX_CHARS`), preferred_language, history, retrieved_context, intent.
	- Xá»­ lÃ½: build prompt gá»n; gá»i LLM `gpt-oss`; stream chunks (SSE). Output: assistant message (final) lÆ°u sau khi stream.
	- Side-effects: lÆ°u DB; enqueue embedding.

- Node 5 â€” Há»i tiáº¿p/Clarify chung
	- Má»¥c Ä‘Ã­ch: Gá»£i má»Ÿ nháº¹ (FollowUp trong persona), giÃºp chuyá»ƒn lÆ°á»£t tiáº¿p theo.
	- Output: 1 cÃ¢u follow-up ngáº¯n (tuá»³ chá»n) rá»“i END lÆ°á»£t.

	Guideline for social/chat requests:
	- If a user makes a social request ("can you hangout with me", "do you want to chat"), the assistant should respond warmly and set boundaries where necessary. Example: acknowledge in the user's language, e.g. EN: "sure, you can speak english with me. I can chat and keep you company here, but I can't meet in person â€” how can I help?"; VI equivalent should be gentle and non-pushy.

- Node 6 â€” END
	- Káº¿t thÃºc lÆ°á»£t; dá»n tÃ i nguyÃªn táº¡m (náº¿u cÃ³).

## Xá»­ lÃ½ Social/Chat Requests

### HÆ°á»›ng dáº«n tÆ°Æ¡ng tÃ¡c xÃ£ giao Má»šI (LLM-Based)
**NguyÃªn táº¯c chÃ­nh**: Bot sá»­ dá»¥ng LLM Ä‘á»ƒ detect vÃ  generate social responses tá»± nhiÃªn, luÃ´n acknowledge user's intent trÆ°á»›c khi dáº«n dáº¯t vá» business.

**LLM Social Detection Process**:
1. **Input Analysis**: LLM phÃ¢n tÃ­ch user message Ä‘á»ƒ xÃ¡c Ä‘á»‹nh social intent
2. **Context Understanding**: Hiá»ƒu Ä‘Æ°á»£c nuance, vÄƒn hÃ³a, vÃ  context
3. **Response Generation**: Táº¡o pháº£n há»“i phÃ¹ há»£p vá»›i giá»ng ná»¯, xÆ°ng hÃ´ "em-quÃ½ khÃ¡ch"
4. **Boundary Setting**: Äáº·t ranh giá»›i há»£p lÃ½ khi cáº§n thiáº¿t
5. **Business Redirect**: Dáº«n dáº¯t nháº¹ nhÃ ng vá» shopping/warranty topics

**VÃ­ dá»¥ conversation (LLM-powered)**:
```
User: em khá»e khÃ´ng
Bot: Em khá»e, cáº£m Æ¡n quÃ½ khÃ¡ch Ä‘Ã£ há»i áº¡. QuÃ½ khÃ¡ch cÃ³ cáº§n em há»— trá»£ vá» thÃ´ng tin hÃ ng hÃ³a hay báº£o hÃ nh khÃ´ng áº¡?

User: Ä‘i chÆ¡i khÃ´ng em  
Bot: Em Ä‘ang lÃ m viá»‡c áº¡, khÃ´ng thá»ƒ Ä‘i chÆ¡i Ä‘Æ°á»£c. QuÃ½ khÃ¡ch cÃ³ cáº§n em há»— trá»£ vá» thÃ´ng tin hÃ ng hÃ³a hay báº£o hÃ nh khÃ´ng áº¡?

User: cÃ³ báº¡n trai khÃ´ng
Bot: Em lÃ  AI nÃªn khÃ´ng cÃ³ chuyá»‡n Ä‘Ã³ áº¡. QuÃ½ khÃ¡ch cÃ³ cáº§n em há»— trá»£ vá» thÃ´ng tin hÃ ng hÃ³a hay báº£o hÃ nh khÃ´ng áº¡?
```

### Æ¯u Ä‘iá»ƒm LLM approach vs Pattern Matching:

**âœ… LLM Benefits**:
- **Flexible & Adaptive**: Hiá»ƒu Ä‘Æ°á»£c cÃ¡c cÃ¡ch diá»…n Ä‘áº¡t má»›i, khÃ´ng giá»›i háº¡n patterns
- **Natural Responses**: Generate pháº£n há»“i tá»± nhiÃªn, phÃ¹ há»£p context
- **Cultural Awareness**: Hiá»ƒu vÄƒn hÃ³a, cÃ¡ch xÆ°ng hÃ´, vÃ  social norms Viá»‡t Nam
- **Contextual Understanding**: Hiá»ƒu Ä‘Æ°á»£c Ã½ nghÄ©a thá»±c sá»±, khÃ´ng chá»‰ keyword matching
- **Consistent Persona**: Maintain giá»ng Ä‘iá»‡u vÃ  personality Ä‘á»“ng nháº¥t

**âŒ Pattern Matching Limitations**:
- Cá»©ng nháº¯c, chá»‰ detect Ä‘Æ°á»£c patterns Ä‘Ã£ Ä‘á»‹nh trÆ°á»›c
- KhÃ´ng hiá»ƒu context vÃ  nuance
- KhÃ³ maintain khi cáº§n thÃªm patterns má»›i
- Responses khÃ´ng tá»± nhiÃªn, cÃ³ thá»ƒ repetitive

### Format pháº£n há»“i chuáº©n (LLM-generated):
`{LLM Social Response}. {Gentle Business Redirect}`

**Business Redirect Options**:
- **VI**: "QuÃ½ khÃ¡ch cÃ³ cáº§n em há»— trá»£ vá» thÃ´ng tin hÃ ng hÃ³a hay báº£o hÃ nh khÃ´ng áº¡?"
- **EN**: "Can I help you with shopping or warranty questions?"

## Persona & Tone

### Persona File (`prompts/system_persona_vi.md`)
**Cáº¥u trÃºc**:
```markdown
Chatbot Persona...

Greeting: [initial greeting cho conversation má»›i]
FollowUp: [append sau responses Ä‘á»ƒ maintain conversation flow]
```

**Äáº·c Ä‘iá»ƒm giá»ng Ä‘iá»‡u**:
- **XÆ°ng hÃ´**: Em (AI) - QuÃ½ khÃ¡ch (User)  
- **Tone**: Lá»‹ch sá»±, thÃ¢n thiá»‡n, ngáº¯n gá»n
- **Female voice**: Nháº¹ nhÃ ng, khÃ´ng Ã©p buá»™c
- **Responsive**: Song ngá»¯ VI/EN based on user preference

### Language Detection & Switch
**Auto-detection**: Dá»±a trÃªn message Ä‘áº§u tiÃªn cá»§a user
- **VI markers**: diacritics, "anh", "em", "khÃ´ng", "dáº¡", "áº¡"
- **EN markers**: "hello", "hi", "please", "how", "what"
- **Default**: VI náº¿u khÃ´ng cháº¯c

**Switch triggers**: "speak english", "tiáº¿ng anh Ä‘Æ°á»£c khÃ´ng", "can we speak english"
**Response**: Immediate ack + language change cho toÃ n bá»™ conversation

## Data & Storage

### AgentState Structure
```python
{
  "conversation_id": str,
  "user_id": str, 
  "chat_history": [{"role": "user|assistant", "content": str}],
  "metadata": {"conversation_id": str, "user_id": str},
  "intent": "shopping|warranty|unknown",
  "intent_confidence": float,
  "need_retrieval_hint": bool,
  "clarify_questions": [str],
  "clarify_attempts": int,
  "preferred_language": "vi|en",
  "retrieved_context": [dict],  # tá»« ChromaDB
  "response": str,              # final response
  "stream": bool
}
```

### Database Schema
**Messages**: id, conversation_id, sender, text, created_at, metadata
**Conversations**: id, user_id, created_at, metadata  
**WarrantyRecords**: serial (PK), product_name, warranty_end_date

### Vector Storage
**ChromaDB**: `./database/chroma_db/`
- Collection: `CHROMA_COLLECTION` env (default: `conversations_dev`)
- Embeddings: `bge-m3` qua Ollama (1024 dimensions)
- Mapping: `messages.id` â†’ vector id
- Metadata: conversation_id, user_id, message_id, created_at

## Warranty Management

### Data Loading (CSV â†’ DB)
**File format** (`knowledge/warranty.csv`):
```csv
serial,product_name,warranty_end_date
ABC123,Laptop Dell,2024-12-31
XYZ789,Mouse Logitech,30/06/2025
```

**Commands**:
```bash
# Validate only
uv run scripts/upsert_warranty_csv.py --file knowledge/warranty.csv --dry-run

# Write to DB  
uv run scripts/upsert_warranty_csv.py --file knowledge/warranty.csv
```

**Date formats**: YYYY-MM-DD hoáº·c DD/MM/YYYY

### Serial Validation Rules
- **Length**: 3-32 characters
- **Characters**: A-Z, a-z, 0-9, dáº¥u gáº¡ch ná»‘i (-)
- **Required**: Ãt nháº¥t 1 chá»¯ sá»‘
- **Forbidden**: Khoáº£ng tráº¯ng internal
- **Regex**: `(?<![A-Za-z0-9-])(?=[A-Za-z0-9-]*\d[A-Za-z0-9-]*)([A-Za-z0-9-]{3,32})(?![A-Za-z0-9-])`

## API (rÃºt gá»n)
- POST /conversations â†’ táº¡o conversation, auto greeting (201)
- POST /conversations/{id}/messages â†’ lÆ°u message (202), assistant flow cháº¡y ná»n
- POST /conversations/{id}/stream â†’ stream cÃ¢u tráº£ lá»i (SSE)
- GET  /conversations/{id}/history â†’ tráº£ lá»‹ch sá»­

## Cáº¥u hÃ¬nh (env chÃ­nh)
- OLLAMA_HOST/PORT, CHROMA_PATH, CHROMA_COLLECTION, DATABASE_URL, X_API_KEYS
- PERSONA_PATH, PERSONA_MAX_CHARS
- INTENT_CONFIDENCE_THRESHOLD

## Pháº§n má»m hoÃ¡ (ngáº¯n)
- Persona ngoÃ i code (`prompts/system_persona_vi.md`): láº¥y Greeting/FollowUp; giá»›i háº¡n bá»Ÿi `PERSONA_MAX_CHARS` khi dá»±ng prompt.
- Clarify loop: khÃ´ng Ä‘áº·t tráº§n; cÃ¢u há»i chuáº©n hoÃ¡ Ä‘á»ƒ Ä‘áº¿m attempts á»•n Ä‘á»‹nh.

## Ghi chÃº triá»ƒn khai & lÃ½ do (4â€“8)

4) Streaming: endpoint vs. thuáº§n graph
- Thá»±c táº¿: endpoint tá»± Ä‘iá»u phá»‘i classify â†’ (clarify|warranty) early exits â†’ retrieve â†’ respond_stream Ä‘á»ƒ Ä‘áº©y chunk SSE ngay.
- LÃ½ do: kiá»ƒm soÃ¡t streaming má»‹n vÃ  Ä‘Æ¡n giáº£n hoÃ¡ I/O SSE. CÃ³ thá»ƒ chuyá»ƒn sang conditional edges trong graph náº¿u cáº§n thuáº§n nháº¥t, nhÆ°ng hiá»‡n táº¡i khÃ´ng báº¯t buá»™c.

5) Khung SSE má»Ÿ Ä‘áº§u
- Thá»±c táº¿: emit `data: {"debug":"stream-open"}` ngay Ä‘áº§u stream.
- LÃ½ do: giÃºp client sá»›m nháº­n biáº¿t káº¿t ná»‘i má»Ÿ, cáº£i thiá»‡n UX vÃ  Ä‘o latency Ä‘áº§u tiÃªn. KhÃ´ng áº£nh hÆ°á»Ÿng ná»™i dung.

6) Prompt ghi chÃº intent
- Thá»±c táº¿: prompt cÃ³ dÃ²ng "Detected intent: <intent>" (náº¿u Ä‘Ã£ xÃ¡c Ä‘á»‹nh).
- LÃ½ do: giÃºp model giá»¯ ngá»¯ cáº£nh má»¥c tiÃªu (tÆ° váº¥n láº¯p rÃ¡p/mua hÃ ng/báº£o hÃ nh) â†’ tráº£ lá»i táº­p trung. Náº¿u muá»‘n trung láº­p, cÃ³ thá»ƒ bá».

7) TÃªn collection Chroma
- Thá»±c táº¿: dÃ¹ng biáº¿n mÃ´i trÆ°á»ng `CHROMA_COLLECTION` (máº·c Ä‘á»‹nh: `conversations_dev`).
- LÃ½ do: linh hoáº¡t dev/prod; script index váº«n cÃ³ thá»ƒ override báº±ng tham sá»‘ `--collection`.

8) FollowUp tá»« persona
- Thá»±c táº¿: follow-up Ä‘Ã£ Ã¡p dá»¥ng á»Ÿ nhÃ¡nh báº£o hÃ nh; Ä‘á»“ng thá»i bá»• sung append follow-up ngáº¯n sau tráº£ lá»i thÆ°á»ng (respond_stream) Ä‘á»ƒ giá»¯ nhá»‹p há»™i thoáº¡i.
- LÃ½ do: tÄƒng tá»‰ lá»‡ tiáº¿p tá»¥c há»™i thoáº¡i; thá»‘ng nháº¥t tÃ´ng giá»ng tá»« persona.

KhÃ¡c biá»‡t nhá» so vá»›i mÃ´ táº£ cÅ©
- â€œÄang chá» serialâ€ hiá»‡n nháº­n diá»‡n qua metadata trÃªn message assistant (`type = warranty_prompt`|`warranty_prompt_invalid`) khi cÃ³, hoáº·c fallback kiá»ƒm tra cÃ¢u chá»¯. LÃ½ do: bá»n vá»¯ng hÆ¡n so vá»›i so khá»›p chuá»—i thuáº§n.
